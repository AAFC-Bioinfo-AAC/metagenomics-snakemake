'''
    Filename: aggregate_minpath_pathways.py
    Author: Devin Holman and Katherine James-Gzyl
    Date created: 2025/09/04
    Snakemake version: 9.9.0
    python version: 3.10

    Script is using the gene-level KEGG Orthology (KO) abundances and aggregating them into pathway-level abundances.
    Filtering is used to only keep pathways confirmed by MinPath.
      1. Read KO mapping list from the KEGG database
      2. Take the MinPath output file generated by rule minpath and extract the MinPath pathway IDs marked as present
      3. Load and clean the KO abundance table that was generated by rule gene_ko_abundance
      4. Map the KOs to pathways
      5. Filter and aggregate to keep only pathways confirmed by MinPath
      6. Save results to [sample]_aggregated_minpath.tsv
'''

import pandas as pd
import sys

# Redirect logging
if hasattr(snakemake, "log") and snakemake.log:
    sys.stdout = open(snakemake.log[0], "w")
    sys.stderr = sys.stdout

# Input/output from Snakemake
ko_abundance_file = snakemake.input["abundance"]
ko_pathway_list = snakemake.input["ko_pathway_list"]
minpath_output_file = snakemake.input["minpath_out"]
pathway_output_file =snakemake.output["minpath_table"]

# Read KO to pathway mapping
ko_pathway_dict = {}
with open(ko_pathway_list, 'r') as f:
    for line in f:
        parts = line.strip().split('\t')
        if len(parts) == 2 and parts[1].startswith("path:ko"):
            ko = parts[0].replace("ko:", "").strip()
            pathway = parts[1].replace("path:ko", "")
            ko_pathway_dict[ko] = pathway

# Get MinPath-confirmed pathways
confirmed_pathways = set()
with open(minpath_output_file, 'r') as f:
    for line in f:
        parts = line.strip().split()
        if len(parts) > 1 and parts[0] == "path":
            confirmed_pathways.add(parts[1])

# Read KO abundance table
df = pd.read_csv(ko_abundance_file, sep='\t')

# Clean KO format
df['KO'] = df['KO'].str.replace('ko:', '', regex=False)

# Map KO to pathway
df['Pathway'] = df['KO'].map(ko_pathway_dict)

# Filter and aggregate
df_filtered = df.dropna(subset=['Pathway'])
df_filtered = df_filtered[df_filtered['Pathway'].isin(confirmed_pathways)]

aggregated_df = df_filtered.groupby('Pathway').agg(
    total_abundance=('Abundance', 'sum'),
    total_rpk=('RPK', 'sum'),
    total_cpm=('Copies_Per_Million_Reads', 'sum')
).reset_index()

aggregated_df.to_csv(pathway_output_file, sep='\t', index=False)