configfile: "config/config.yaml"

from dotenv import load_dotenv
import csv, os, sys

# -------------------------------------------------------------------
# Environment and project paths
# -------------------------------------------------------------------

PIPELINE_DIR = os.getcwd()
ENV_FILE = os.path.join(PIPELINE_DIR, ".env")

# Load env file
load_dotenv(ENV_FILE, override=True)

PROJECT_ROOT = os.getenv("PROJECT_ROOT")
if not PROJECT_ROOT:
    raise ValueError("PROJECT_ROOT not set in .env")
## Compose all other important paths, always relative to PROJECT_ROOT
CONFIG_DIR     = os.path.join(PIPELINE_DIR, "config")

# -------------------------------------------------------------------
# TMPDIR setup
# -------------------------------------------------------------------

user = os.environ.get("USER")
if not user:
    raise ValueError("Environment variable USER is not set.")

fallback_tmpdir = f"/gpfs/fs7/aafc/scratch/{user}/tmpdir/malate"
TMPDIR = os.path.expandvars(os.getenv("TMPDIR", fallback_tmpdir))
os.makedirs(TMPDIR, exist_ok=True)

# -------------------------------------------------------------------
# CARD DB setup
# -------------------------------------------------------------------

def validate_card_db(path):
    """Ensure CARD DB has required files."""
    def has_fasta(p):
        return (
            os.path.exists(os.path.join(p, "card_reference.fasta")) or
            any(name.endswith(".fasta") for name in os.listdir(p))
        )
    if not (os.path.exists(os.path.join(path, "card.json")) and has_fasta(path)):
        sys.exit(
            f"\nERROR: CARD DB not properly prepared at {path} "
            "(missing card.json or .fasta). See pipeline README.\n"
        )

env_rgi_card = os.getenv("RGI_CARD", "").strip()
if env_rgi_card:
    RGI_CARD = env_rgi_card
elif "card_latest" in config:
    cfg_card = config["card_latest"]
    RGI_CARD = os.path.join(PROJECT_ROOT, cfg_card) if not os.path.isabs(cfg_card) else cfg_card
else:
    raise ValueError("You must set RGI_CARD in .env or card_latest in config.yaml!")

if not os.path.exists(RGI_CARD):
    sys.exit(f"\nERROR: RGI_CARD path not found: {RGI_CARD}\n")

validate_card_db(RGI_CARD)

# -------------------------------------------------------------------
# Config-derived paths
# -------------------------------------------------------------------

def relpath(cfg_key):
    """Resolve a config path relative to PROJECT_ROOT."""
    return os.path.join(PROJECT_ROOT, config[cfg_key])
    
CONDA_PREFIX = relpath("conda_prefix")
READS_DIR         = relpath("reads_dir")
TRIMMED_DIR       = os.path.join(TMPDIR, config["reads_trimmed"])
HOST_DEP_DIR      = relpath("reads_host_dep")
MERGED_R1_R2      = relpath("merged_reads")
KRAKEN_OUTPUT_DIR = relpath("kraken_short_reads_dir")
BRACKEN_OUTPUT_DIR= relpath("bracken_short_reads_dir")
CARD_RGI_OUTPUT_DIR= relpath("amr_screening_dir")
KEGG_OUTPUT_DIR   = relpath("kegg_output_dir")
SAMPLE_ASSEMBLY   = relpath("mag_output_dir")
LOG_DIR           = relpath("log_files")
SOFTWARE_VERSIONS = relpath("software_versions")
KEGG_DIAMOND      = relpath("kegg_diamond_DB")
KEGG_CUSTOM_LIST  = relpath("kegg_custom_list")

BOWTIE_INDEX      = relpath("bowtie2_index")
BOWTIE_INDEX_FILES= [f"{BOWTIE_INDEX}.{i}.bt2" for i in (1,2,3,4)] + \
                    [f"{BOWTIE_INDEX}.rev.{i}.bt2" for i in (1,2)]

TAXONOMY_DB       = config["gtbd_DB"]
KEGG_KO           = config["ko_lists"]
KEGG_FASTA        = config["kegg_fasta"]
KEGG_BRITE_HIERARCHY = config["kegg_brite_hierarchy"]
CHECKM2_DB        = config["checkm2_DB"]


# -------------------------------------------------------------------
# Sample handling
# -------------------------------------------------------------------

SAMPLESHEET_PATH = os.path.join(CONFIG_DIR, config["samplesheet"])

def load_samples(samplesheet):
    samples = {}
    with open(samplesheet, newline="") as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            samples[row["sample"]] = {
                "fastq_1": os.path.join(READS_DIR, row["fastq_1"]),
                "fastq_2": os.path.join(READS_DIR, row["fastq_2"]),
            }
    return samples

SAMPLES = load_samples(SAMPLESHEET_PATH)
SAMPLE_NAMES = list(SAMPLES.keys())

# -------------------------------------------------------------------
# Helpers
# -------------------------------------------------------------------
sys.path.append(os.path.join(os.path.dirname(__file__), "scripts"))

from scripts.helpers import bowtie2_index_files, parse_filtered_samples

def get_filtered_samples(wildcards):
    ckpt_output = checkpoints.filter_nonempty_assemblies.get(**wildcards).output[0]
    return parse_filtered_samples(ckpt_output)

def get_filtered_list_file(wildcards):
    return checkpoints.filter_nonempty_assemblies.get(**wildcards).output[0]

def get_all_bowtie2_indices(wildcards):
    return [
        f for s in get_filtered_samples(wildcards)
        for f in bowtie2_index_files(s, SAMPLE_ASSEMBLY)
    ]

# -------------------------------------------------------------------
# Rules
# -------------------------------------------------------------------
include: "rules/preprocessing.smk"
include: "rules/taxonomy.smk"
include: "rules/amr_short_reads.smk"
include: "rules/kegg.smk"  #KEGG DATABASE NOT ACCESSIBLE
include: "rules/mag.smk"
include: "rules/env_versions.smk"

## Rule outputs files ##
rule all:
    input:
        # Ensure checkpoint runs first
        get_filtered_list_file,

        # Reads depleted of host and PhiX
        expand(f"{HOST_DEP_DIR}/{{sample}}_trimmed_clean_R1.fastq.gz", sample=SAMPLES),
        expand(f"{HOST_DEP_DIR}/{{sample}}_trimmed_clean_R2.fastq.gz", sample=SAMPLES),

        # Taxonomy with Kraken
        expand(f"{KRAKEN_OUTPUT_DIR}/{{sample}}.report.txt", sample=SAMPLES),
        expand(f"{KRAKEN_OUTPUT_DIR}/{{sample}}.kraken", sample=SAMPLES),

        # Taxonomy with Bracken
        expand(f"{BRACKEN_OUTPUT_DIR}/species/{{sample}}_bracken.species.report.txt", sample=SAMPLES),
        expand(f"{BRACKEN_OUTPUT_DIR}/genus/{{sample}}_bracken.genus.report.txt", sample=SAMPLES),
        expand(f"{BRACKEN_OUTPUT_DIR}/phylum/{{sample}}_bracken.phylum.report.txt", sample=SAMPLES),
        expand(f"{BRACKEN_OUTPUT_DIR}/domain/{{sample}}_bracken.domain.report.txt", sample=SAMPLES),
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_species.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_genus.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_phylum.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_domain.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_species_cleaned.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_genus_cleaned.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_phylum_cleaned.txt",
        f"{BRACKEN_OUTPUT_DIR}/merged_abundance_domain_cleaned.txt",
        f"{BRACKEN_OUTPUT_DIR}/bracken_cleaned_adjusted_species.txt",
        f"{BRACKEN_OUTPUT_DIR}/bracken_cleaned_adjusted_genus.txt",
        f"{BRACKEN_OUTPUT_DIR}/bracken_cleaned_adjusted_phylum.txt",

        # Merged/parsed bracken tables
        f"{BRACKEN_OUTPUT_DIR}/bracken_species_raw_abundance.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_species_rel_abundance_default.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_species_rel_abundance_adjusted.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_genus_raw_abundance.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_genus_rel_abundance_default.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_genus_rel_abundance_adjusted.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_phylum_raw_abundance.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_phylum_rel_abundance_default.csv",
        f"{BRACKEN_OUTPUT_DIR}/bracken_phylum_rel_abundance_adjusted.csv",

        # AMR screening with RGI BWT
        expand(f"{CARD_RGI_OUTPUT_DIR}/{{sample}}/{{sample}}_paired.allele_mapping_data.txt", sample=SAMPLES),

        # KEGG and MinPath
        expand(f"{MERGED_R1_R2}/{{sample}}_merged.fastq.gz", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_diamond_output.m8", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_read_count.txt", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_gene_ko_abundance.tsv", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_ko_list_raw.txt", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_ko_list_fixed.txt", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_minpath_output.txt", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_aggregated_minpath.tsv", sample=SAMPLES),
        expand(f"{KEGG_OUTPUT_DIR}/{{sample}}/{{sample}}_ko_pathway_abundance_with_category.tsv", sample=SAMPLES),
        f"{KEGG_OUTPUT_DIR}/combined_ko_pathway_abundance_with_category.tsv",
        f"{KEGG_OUTPUT_DIR}/combined_ko_pathway_abundance_with_category_filtered.tsv",

        # Individual assemblies with MEGAHIT
        expand(f"{SAMPLE_ASSEMBLY}/{{sample}}_assembly.contigs.fa", sample=SAMPLES),
        expand(f"{SAMPLE_ASSEMBLY}/{{sample}}.bam", sample=SAMPLES),
        expand(f"{SAMPLE_ASSEMBLY}/metabat2/{{sample}}/{{sample}}_depth.txt", sample=SAMPLES),
        expand(f"{SAMPLE_ASSEMBLY}/metabat2/{{sample}}/bins", sample=SAMPLES),
        expand(f"{SAMPLE_ASSEMBLY}/metabat2/{{sample}}/unbinned", sample=SAMPLES),
        expand(f"{SAMPLE_ASSEMBLY}/metabat2/{{sample}}/checkm2/", sample=SAMPLES),
        expand(f"{SAMPLE_ASSEMBLY}/metabat2/{{sample}}/checkm2/quality_report.tsv", sample=SAMPLES),

        # Bowtie2 indices for non-empty assemblies only
        get_all_bowtie2_indices,

        # Required logs or done markers
        f"{LOG_DIR}/rgi_reload_db.done",
        f"{LOG_DIR}/rgi_symlink.done",
        f"{LOG_DIR}/prokaryotes_db_done.txt",

        # Software versions report
        f"{SOFTWARE_VERSIONS}/software_versions_summary.txt",
        f"{SOFTWARE_VERSIONS}/key_bioinformatics_software.txt",
        f"{SOFTWARE_VERSIONS}/key_bioinformatics_software.html"
        
